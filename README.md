# emoPLMsynth
Repository for our EMNLP 2023 Findings Paper: "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition"



## Citation (BibTeX)
Please use the citation below if using our work, thank you.
```
@inproceedings{cowap-etal-2023-stochastic,
    title = "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition",
    author = "Cowap, Alan  and
      Graham, Yvette  and
      Foster, Jennifer",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.665",
    doi = "10.18653/v1/2023.findings-emnlp.665",
    pages = "9928--9946",
    abstract = "Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth",
}
```


[Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition](https://aclanthology.org/2023.findings-emnlp.665) (Cowap et al., Findings 2023)

Alan Cowap, Yvette Graham, and Jennifer Foster. 2023. Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9928â€“9946, Singapore. Association for Computational Linguistics.

## Ethical Considerations
Care must be taken when using these language models (emoPLMsynth and PLMsynth), and datasets (NEWSsynth and ChatGPT100) as they may produce or contain ethically problematic content. Data scraped from the web may contain content which is ethically problematic such as adult content, bias, toxicity etc. and web-scraped data is used in the pre-trained language models such as BERT, BLOOM and Grover. PLMsynth and emoPLMsynth are based on BERT or BLOOM PLMs, while NEWSsynth was generated by Grover. Consequently, emoPLMsynth and PLMsynth could produce text which is ethically problematic, while NEWSsynth may contain ethically problematic content. As a result, any use of the language models (emoPLMsynth, PLMsynth) or the datasets (NEWSsynth or ChatGPT100) should employ appropriate checks and test regimes to handle potential harmful content.

Please read our paper (links above) for more information on our Experiments, Usage, Limitations, etc.
